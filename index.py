from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
import json
import time

def flatten_metadata(md):
    flat = {}
    for k, v in md.items():
        if v is None:
            flat[k] = ""  # Chroma –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç None, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
        elif isinstance(v, (list, dict)):
            flat[k] = json.dumps(v, ensure_ascii=False)
        else:
            flat[k] = v
    return flat

with open("/Users/zarinamacbook/rag_system/main_copy.json", "r", encoding="utf-8") as f:
    docs_raw = json.load(f)

print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs_raw)}")

docs = []
for d in docs_raw:
    content = d.get("content", "")
    metadata = d.get("metadata", {})  # –µ—Å–ª–∏ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
    docs.append(
        Document(
            page_content=content,
            metadata=flatten_metadata(metadata)
        )
    )

print("üìù –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –≤ LangChain Documents.")
print("‚è≥ –ù–∞—á–∏–Ω–∞—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é...")

embeddings = OllamaEmbeddings(model="llama3")

batch_size = 20
vectorstore = None
for i in range(0, len(docs), batch_size):
    batch = docs[i:i+batch_size]
    print(f"  üü¶ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ {i+1} ‚Äî {min(i+batch_size, len(docs))} ...")
    if vectorstore is None:
        vectorstore = Chroma.from_documents(
            batch, embedding=embeddings, persist_directory="./chroma_db"
        )
    else:
        vectorstore.add_documents(batch)
    print(f"  ‚úÖ {min(i+batch_size, len(docs))} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ.")
    time.sleep(0.5)

vectorstore.persist()

print("üéâ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
